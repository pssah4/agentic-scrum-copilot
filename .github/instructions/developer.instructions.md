---
applyTo: "backlog/tasks/**/*.md, src/**/*.{py,js,ts}, tests/**/*.{py,js,ts}, logs/**/*.md"
description: "Automatische Validierungs- und QualitÃ¤tsregeln fÃ¼r Development mit Test-Enforcement"
autoLoad: true
---

# Developer - Validation & Quality Rules (Test-Enforced)

Diese Instructions werden **automatisch** angewendet beim Arbeiten mit Task-Files, Source Code und Tests. Sie ergÃ¤nzen den Developer Chatmode mit spezifischen Validierungs- und Quality-Checks fÃ¼r **MANDATORY Testing**.

> **Wichtig:** Diese Regeln gelten zusÃ¤tzlich zu `.github/chatmodes/developer.chatmode.md`

## ðŸ“ UnterstÃ¼tzte Dateitypen

Diese Validierungsregeln greifen bei:

```
âœ… backlog/tasks/**/*.md (Task Files)
âœ… src/**/*.py (Source Code)
âœ… tests/**/*.py (Test Files)
âœ… logs/ERROR-TASK-*.md (Error Logs - beim Erstellen)
```

---

## ðŸ” Automatische Validierungen

### 1. Task File Reading Validation

**Pattern-Validierung:**

```javascript
// Task File Pattern
const taskPattern = /^TASK-\d{3}-\d{3}-[a-z0-9-]+\.md$/;

// Beispiel:
// TASK-001-001-create-user-model.md
```

**Required Sections beim Lesen:**

```markdown
MANDATORY Sections (vor Start):

âœ… ## Description
âœ… ## Technical Specification
   - Files to Create/Modify
   - Implementation Details (mit Code!)
âœ… ## Test Plan (CRITICAL!)
   - Unit Tests
   - Integration Tests (if applicable)
âœ… ## Acceptance Criteria
âœ… ## Definition of Done

OPTIONAL aber empfohlen:
â—‹ ## Dependencies
â—‹ ## Edge Cases
```

**Fehlermeldung bei ungÃ¼ltigem Task:**

```
âŒ Task File ungÃ¼ltig oder unvollstÃ¤ndig

Datei: backlog/tasks/FEATURE-001/task-1-setup.md
Probleme: 2

1. âŒ Dateiname nicht korrekt
   Gefunden: task-1-setup.md
   Erwartet: TASK-001-001-setup-database.md
   
   Format: TASK-{FEATURE-ID}-{TASK-NUM}-{slug}.md

2. âŒ Test Plan Section fehlt
   Task enthÃ¤lt keine Test-Spezifikation
   
   â†’ CRITICAL: Kann nicht ohne Test Plan starten!
   â†’ BenÃ¶tigt: Architect muss Test Plan hinzufÃ¼gen

Action erforderlich:
  Task ist nicht implementation-ready.
  Benachrichtige @architect zur VervollstÃ¤ndigung.
```

---

### 2. Implementation Quality Checks

**WÃ¤hrend Implementation (Phase 3):**

```markdown
CHECK wÃ¤hrend Code-Erstellung:

âœ… Folgt Task-Spezifikation?
âœ… Type Hints vorhanden?
âœ… Docstrings vollstÃ¤ndig?
âœ… Input Validation implementiert?
âœ… Error Handling vorhanden?
âœ… Keine hardcoded Werte?
âœ… Keine TODOs oder Platzhalter?
âœ… Clean Code Principles befolgt?

VERBOTEN:
âŒ Code ohne Type Hints (Python/TypeScript)
âŒ Funktionen ohne Docstrings
âŒ Keine Input Validation
âŒ Bare except: ohne Fehlerbehandlung
âŒ print() statt logging
âŒ Hardcoded Secrets
âŒ TODOs in Production Code
âŒ Commented-out Code
```

**Code Quality Example - BAD:**

```python
# âŒ BAD IMPLEMENTATION
def process_user(data):
    try:
        user = data['user']
        print(user)  # Debug print
        # TODO: Add validation
        return user
    except:  # Bare except
        return None
```

**Code Quality Example - GOOD:**

```python
# âœ… GOOD IMPLEMENTATION
import logging
from typing import Dict, Optional

logger = logging.getLogger(__name__)

def process_user(data: Dict) -> Optional[User]:
    """
    Process user data from request.
    
    Args:
        data: Request data containing user info
        
    Returns:
        User object if valid, None otherwise
        
    Raises:
        ValueError: If user data is invalid
        
    Examples:
        >>> process_user({'user': {'id': 1, 'name': 'John'}})
        User(id=1, name='John')
    """
    if 'user' not in data:
        logger.error("Missing 'user' key in data")
        raise ValueError("User data must contain 'user' key")
    
    user_data = data['user']
    
    if not isinstance(user_data, dict):
        logger.error(f"Invalid user data type: {type(user_data)}")
        raise ValueError("User data must be a dictionary")
    
    try:
        user = User.from_dict(user_data)
        logger.info(f"Successfully processed user: {user.id}")
        return user
    except ValidationError as e:
        logger.error(f"User validation failed: {e}")
        raise
```

**Fehlermeldung bei schlechtem Code:**

```
âš ï¸ Code Quality Issues erkannt

Datei: src/users.py
Function: process_user
Probleme: 5

1. âŒ Keine Type Hints
   Zeile 1: def process_user(data):
   Fix: def process_user(data: Dict) -> Optional[User]:

2. âŒ Fehlender Docstring
   Function hat keine Dokumentation
   Fix: FÃ¼ge vollstÃ¤ndigen Docstring hinzu

3. âŒ Keine Input Validation
   Function akzeptiert beliebige Input ohne Check
   Fix: Validiere 'user' key existiert und ist dict

4. âŒ Bare except clause
   Zeile 5: except:
   Fix: except ValidationError as e: + logging

5. âŒ print() statt logging
   Zeile 4: print(user)
   Fix: logger.info(f"Processing user: {user.id}")

Action erforderlich:
  Refactor Code gemÃ¤ÃŸ Clean Code Principles.
  Reference: .github/chatmodes/developer.chatmode.md
```

---

### 3. Test Creation Validation (MANDATORY!)

**Test-Erstellungs-Check (Phase 4):**

```markdown
CHECK wÃ¤hrend Test-Erstellung:

âœ… ALLE Test Cases aus Task Test Plan implementiert?
âœ… Unit Tests geschrieben?
âœ… Integration Tests geschrieben (if applicable)?
âœ… Edge Cases getestet?
âœ… Error Cases getestet?
âœ… Parametrized Tests fÃ¼r multiple Scenarios?
âœ… Test Namen beschreibend?
âœ… Docstrings in Tests?
âœ… Keine "pass" oder "TODO" Tests?

MINIMUM Requirements:
âœ… 1x Happy Path Test
âœ… 1x Edge Case Test
âœ… 1x Error Case Test
âœ… Alle Tests aus Task Test Plan

VERBOTEN:
âŒ Tests Ã¼berspringen
âŒ "TODO: Write test" Platzhalter
âŒ Tests die nur "pass" enthalten
âŒ UnvollstÃ¤ndige Tests
âŒ Tests ohne Assertions
```

**Test Example - BAD:**

```python
# âŒ BAD TESTS
def test_user():
    pass  # TODO: Write test

def test_user2():
    user = create_user()
    # No assertion!
```

**Test Example - GOOD:**

```python
# âœ… GOOD TESTS
import pytest
from src.users import create_user, UserValidationError

class TestUserCreation:
    """Tests for user creation functionality."""
    
    def test_create_user_with_valid_data(self):
        """Test user creation with all valid fields."""
        user = create_user(
            email="test@example.com",
            password="SecurePass123!",
            name="John Doe"
        )
        assert user.email == "test@example.com"
        assert user.name == "John Doe"
        assert user.is_active is True
        assert user.is_verified is False
    
    def test_create_user_without_name(self):
        """Test user creation with optional name field empty."""
        user = create_user(
            email="test@example.com",
            password="SecurePass123!"
        )
        assert user.email == "test@example.com"
        assert user.name is None
    
    def test_create_user_with_invalid_email(self):
        """Test error handling for invalid email format."""
        with pytest.raises(UserValidationError, match="Invalid email"):
            create_user(
                email="invalid-email",
                password="SecurePass123!"
            )
    
    def test_create_user_with_weak_password(self):
        """Test error handling for password validation."""
        with pytest.raises(UserValidationError, match="Password too weak"):
            create_user(
                email="test@example.com",
                password="123"
            )
    
    @pytest.mark.parametrize("email,password,expected_error", [
        ("", "Pass123!", "Email cannot be empty"),
        ("test@example.com", "", "Password cannot be empty"),
        ("invalid", "Pass123!", "Invalid email format"),
    ])
    def test_create_user_validation_errors(self, email, password, expected_error):
        """Test various validation error scenarios."""
        with pytest.raises(UserValidationError, match=expected_error):
            create_user(email=email, password=password)
```

**Fehlermeldung bei unvollstÃ¤ndigen Tests:**

```
âŒ Test Suite unvollstÃ¤ndig

Datei: tests/unit/test_users.py
Function: create_user
Probleme: 4

1. âŒ Nur 2 Tests geschrieben
   Gefunden: test_user, test_user2
   Task Test Plan verlangt: 5 Tests
   
   Fehlende Tests:
   - test_create_user_with_invalid_email()
   - test_create_user_with_weak_password()
   - test_create_user_validation_errors() (parametrized)

2. âŒ Kein Edge Case Test
   Keine Tests fÃ¼r Boundary Conditions
   
   â†’ FÃ¼ge hinzu:
     - test_create_user_with_empty_name()
     - test_create_user_with_max_length_fields()

3. âŒ Fehlende Error Case Tests
   Keine Tests fÃ¼r Fehlerbehandlung
   
   â†’ FÃ¼ge hinzu:
     - test_create_user_with_invalid_data()
     - test_create_user_database_error()

4. âŒ Test Platzhalter gefunden
   Zeile 45: def test_user(): pass  # TODO
   
   â†’ Implementiere vollstÃ¤ndigen Test

Action erforderlich:
  Tests sind MANDATORY. Implementiere ALLE fehlenden Tests
  aus Task Test Plan bevor Task als complete markiert wird.
```

---

### 4. Test Execution Validation (MANDATORY!)

**CRITICAL: Test-AusfÃ¼hrung ist NICHT optional!**

```markdown
CHECK wÃ¤hrend Test-Execution (Phase 5):

âœ… Affected tests executed?
âœ… ALL unit tests executed?
âœ… ALL integration tests executed?
âœ… Coverage check executed?
âœ… Test results dokumentiert?

MANDATORY Test Commands:
$ pytest tests/unit/ -v --tb=short
$ pytest tests/integration/ -v --tb=short
$ pytest tests/ --cov=src --cov-report=term

VERBOTEN:
âŒ "Tests probably pass"
âŒ Nur affected tests run
âŒ Skip integration tests
âŒ Ignore test failures
âŒ Continue ohne test execution
âŒ Mock test results
```

**Test Execution Results Required:**

```bash
# MUST BE DOCUMENTED:

Test Execution Results:
âœ… Unit Tests: X/X passed
âœ… Integration Tests: Y/Y passed
âœ… Coverage: Z% (threshold: 90%)
âœ… Execution Time: N seconds

OR if failed:
âŒ Unit Tests: X/Y passed, Z FAILED
âŒ Integration Tests: A/B passed, C FAILED
â†’ Error Log MUST be created
```

**Fehlermeldung bei fehlender Test-AusfÃ¼hrung:**

```
âŒ CRITICAL: Tests nicht ausgefÃ¼hrt!

Task: TASK-001-001-create-user-model
Status: Implementation complete
Test Execution: âŒ MISSING

Problem: Task kann NICHT als complete markiert werden ohne:
  1. ALLE Tests ausgefÃ¼hrt
  2. ALLE Tests passing
  3. Test Results dokumentiert

Action erforderlich:
  FÃ¼hre folgende Commands aus:
  
  $ pytest tests/unit/test_users.py -v
  $ pytest tests/unit/ -v
  $ pytest tests/integration/ -v
  $ pytest tests/ --cov=src --cov-report=term
  
  Dokumentiere Results im Task-Commit.

MANDATORY: No Code ships without test execution!
```

---

### 5. Test Failure Handling (MANDATORY!)

**Wenn Tests fehlschlagen:**

```markdown
CHECK bei Test-Failures:

âœ… Error Log erstellt?
âœ… Error Log Format korrekt?
âœ… Alle Failures dokumentiert?
âœ… Stack Traces enthalten?
âœ… Code Context enthalten?
âœ… Environment Info enthalten?
âœ… @debugger notified?
âœ… Task execution STOPPED?

MANDATORY Error Log Creation:
File: logs/ERROR-TASK-{FEATURE}-{TASK}-{YYYY-MM-DD}-{HHMM}.md

VERBOTEN:
âŒ Test-Failures ignorieren
âŒ "Will fix later"
âŒ Commit trotz failing tests
âŒ Continue to next task
âŒ Mark task as complete
```

**Error Log Template Required:**

```markdown
# Error Log: TASK-XXX-YYY

**Task ID:** TASK-XXX-YYY  
**Task Title:** [Title]  
**Date:** YYYY-MM-DD HH:MM  
**Developer:** Developer Mode  
**Status:** âŒ Tests Failed  

## Error Summary
**Failed Tests:** X out of Y tests failed  
**Test Type:** Unit | Integration | Both  
**Severity:** High | Medium | Low

## Test Failures
[Detaillierte Test-Failure-Info]

## Code Context
[Relevanter Code]

## Environment Information
[Environment Details]

## Attempted Solutions
[Was wurde versucht]

## Next Steps for @debugger
[Was Debugger analysieren soll]
```

**Fehlermeldung bei fehlender Error Log Creation:**

```
âŒ CRITICAL: Error Log nicht erstellt!

Test Results:
âŒ Unit Tests: 12/15 passed, 3 FAILED
âŒ Integration Tests: 5/8 passed, 3 FAILED

MANDATORY Action:
  Wenn Tests fehlschlagen, MUSS Error Log erstellt werden!

Action erforderlich:
  1. Erstelle: logs/ERROR-TASK-001-001-2025-10-07-1430.md
  2. Dokumentiere ALLE Test Failures
  3. Include Stack Traces
  4. Include Code Context
  5. Include Environment Info
  6. Notify @debugger
  7. STOP Task Execution

Template: .github/templates/ERROR-LOG-TEMPLATE.md

UNTIL Error Log created, task is BLOCKED!
```

---

### 6. Acceptance Criteria Validation

**Vor Marking Task Complete:**

```markdown
CHECK Acceptance Criteria:

âœ… Alle Criteria aus Task erfÃ¼llt?
âœ… Functionality wie spezifiziert?
âœ… Edge Cases behandelt?
âœ… Performance akzeptabel?
âœ… Keine Regressionen?

ALLE Criteria mÃ¼ssen âœ… sein:
- [ ] Criterion 1 aus Task
- [ ] Criterion 2 aus Task
- [ ] Criterion 3 aus Task
- [ ] ALL Tests passed
- [ ] Coverage >90%

VERBOTEN:
âŒ "Mostly works"
âŒ "Good enough"
âŒ UnerfÃ¼llte Criteria ignorieren
```

**Fehlermeldung bei unerfÃ¼llten Criteria:**

```
âš ï¸ Acceptance Criteria nicht erfÃ¼llt

Task: TASK-001-001-create-user-model
Status: Implementation complete
Acceptance Criteria: 3/5 âœ…

ErfÃ¼llte Criteria:
  âœ… User model has all required fields
  âœ… Email field has unique constraint
  âœ… Migration runs successfully

Nicht erfÃ¼llte Criteria:
  âŒ Timestamps auto-update
     â†’ created_at/updated_at nicht automatisch
  âŒ All tests pass
     â†’ 2 Tests failing

Action erforderlich:
  Fix unerfÃ¼llte Criteria:
  
  1. Timestamps auto-update:
     Add server_default=func.now() and onupdate=func.now()
  
  2. Fix failing tests:
     Run tests und behebe Failures

Task kann NICHT als complete markiert werden bis
ALLE Acceptance Criteria erfÃ¼llt sind!
```

---

### 7. Definition of Done Validation

**Final Check vor Commit:**

```markdown
CHECK Definition of Done:

âœ… Code implemented as specified?
âœ… Unit tests written and passing?
âœ… Integration tests written and passing?
âœ… Code reviewed (self-review)?
âœ… Documentation updated?
âœ… No TODOs oder Platzhalter?
âœ… Clean Code Principles befolgt?
âœ… BACKLOG.md Code-Mapping bereit?

ALLE Items mÃ¼ssen âœ… sein!

VERBOTEN:
âŒ "Almost done"
âŒ Skip DoD Items
âŒ "Will do later"
```

**Fehlermeldung bei unvollstÃ¤ndigem DoD:**

```
âŒ Definition of Done nicht erfÃ¼llt

Task: TASK-001-001-create-user-model
DoD Status: 5/7 âœ…

ErfÃ¼llte Items:
  âœ… Code implemented as specified
  âœ… Unit tests written and passing
  âœ… Integration tests written and passing
  âœ… Code reviewed (self-review)
  âœ… No TODOs oder Platzhalter

Nicht erfÃ¼llte Items:
  âŒ Documentation updated
     â†’ Docstrings vorhanden, aber README nicht updated
  âŒ BACKLOG.md Code-Mapping prepared
     â†’ Code-Mapping fehlt fÃ¼r Task

Action erforderlich:
  1. Update README.md:
     FÃ¼ge User Model Dokumentation hinzu
  
  2. Prepare Code-Mapping:
     Erstelle Entry fÃ¼r BACKLOG.md:
     Code: `src/models/user.py`, `tests/unit/test_user_model.py`

Task kann NICHT committed werden bis DoD 100% erfÃ¼llt!
```

---

### 8. Commit Message Validation

**Commit Message Quality Check:**

```markdown
CHECK Commit Message:

âœ… Type correct? (feat|fix|test|docs|refactor|chore)
âœ… Scope present?
âœ… Brief description clear?
âœ… Implementation section vorhanden?
âœ… Testing section vorhanden?
âœ… Test results dokumentiert?
âœ… References Task?
âœ… References Feature/Issue?

Format:
type(scope): TASK-XXX-YYY - Brief description

Implementation:
- Change 1
- Change 2

Testing:
- Unit tests: X passing
- Integration tests: Y passing
- Coverage: Z%

Closes TASK-XXX-YYY
References FEATURE-XXX, ISSUE-XXX
```

**Beispiel - BAD Commit:**

```
âŒ BAD:
"added user model"

Problems:
1. No type
2. No scope
3. No task reference
4. No testing info
```

**Beispiel - GOOD Commit:**

```
âœ… GOOD:
feat(models): TASK-001-001 - create User database model

Implementation:
- Created User model with email, password_hash fields
- Added unique constraint on email
- Added automatic timestamps (created_at, updated_at)
- Created Alembic migration for users table

Testing:
- Unit tests: 15/15 passing
- Integration tests: 8/8 passing
- Coverage: 94%

Closes TASK-001-001
References FEATURE-001, ISSUE-001
```

**Fehlermeldung bei schlechter Commit Message:**

```
âš ï¸ Commit Message unzureichend

Gefunden: "added user model"

Probleme:
1. âŒ Kein Type (feat|fix|...)
2. âŒ Kein Scope (models)
3. âŒ Kein Task Reference
4. âŒ Keine Implementation Details
5. âŒ Keine Testing Information
6. âŒ Keine References

Action erforderlich:
  Schreibe informative Commit Message mit:
  - Type und Scope
  - Task Reference
  - Implementation Details
  - Testing Results
  - References zu Feature/Issue

Template: .github/templates/COMMIT-MESSAGE-TEMPLATE.txt
```

---

## ðŸŽ¯ Test-Enforcement Rules (CANNOT BE BYPASSED)

**Diese Regeln sind NICHT optional:**

### Rule 1: No Code Without Tests

```
âŒ NICHT ERLAUBT:
- Code schreiben ohne Tests
- Tests "spÃ¤ter" schreiben
- Tests Ã¼berspringen

âœ… MANDATORY:
- Tests schreiben (Phase 4)
- Tests ausfÃ¼hren (Phase 5)
- Tests passing (Phase 5)
```

### Rule 2: ALL Tests Must Pass

```
âŒ NICHT ERLAUBT:
- Commit mit failing tests
- "Most tests pass"
- Failing tests ignorieren

âœ… MANDATORY:
- 100% Tests passing
- Error Log if failures
- @debugger notification
```

### Rule 3: Comprehensive Testing Required

```
âŒ NICHT ERLAUBT:
- Nur affected tests run
- Skip integration tests
- "Assume tests pass"

âœ… MANDATORY:
- ALL unit tests run
- ALL integration tests run
- Coverage check performed
```

### Rule 4: Error Logs for Failures

```
âŒ NICHT ERLAUBT:
- Continue without Error Log
- Skip Error Log creation
- "Will fix myself"

âœ… MANDATORY:
- Create Error Log immediately
- Document all failures
- Notify @debugger
- STOP task execution
```

### Rule 5: Coverage Maintained

```
âŒ NICHT ERLAUBT:
- Coverage drop below 90%
- "Coverage doesn't matter"
- Skip coverage check

âœ… MANDATORY:
- Maintain >90% coverage
- New code 100% coverage
- Coverage check in tests
```

---

## ðŸ“Š Quality Gate Development (QGD)

**Pre-Commit Validation:**

```markdown
QGD Check:

Phase 1: Task Understanding
âœ… Task file valid and complete?
âœ… Test Plan present and clear?

Phase 2: Dependencies
âœ… All dependency tasks complete?
âœ… Environment ready?

Phase 3: Implementation
âœ… Code follows specification?
âœ… Clean Code Principles applied?
âœ… No TODOs or placeholders?

Phase 4: Test Creation (CRITICAL!)
âœ… ALL tests from Test Plan written?
âœ… Edge cases covered?
âœ… Error cases covered?
âœ… Test quality good?

Phase 5: Test Execution (CRITICAL!)
âœ… ALL tests executed?
âœ… ALL tests passing?
âœ… Coverage >90%?
âœ… No regressions?

Phase 6: Acceptance Criteria
âœ… All criteria fulfilled?

Phase 7: Definition of Done
âœ… All DoD items checked?

Phase 8: Commit
âœ… Commit message informative?
âœ… Code-Mapping prepared?

Wenn ALLE âœ…:
  â†’ Commit allowed
  â†’ Update BACKLOG.md
  â†’ Continue to next task

Wenn EIN âŒ:
  â†’ BLOCK Commit
  â†’ Show specific failure
  â†’ Require fix
```

**QGD Report Format:**

```
ðŸš€ QGD (Quality Gate Development) Check: TASK-001-001

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: Task Understanding âœ…         â”‚
â”‚ Phase 2: Dependencies âœ…               â”‚
â”‚ Phase 3: Implementation âœ…             â”‚
â”‚ Phase 4: Test Creation âœ…              â”‚
â”‚   - Unit Tests: 15 tests written       â”‚
â”‚   - Edge Cases: 5 tests                â”‚
â”‚   - Error Cases: 3 tests               â”‚
â”‚ Phase 5: Test Execution âœ…             â”‚
â”‚   - Unit Tests: 15/15 passing          â”‚
â”‚   - Integration: 8/8 passing           â”‚
â”‚   - Coverage: 94% (>90% âœ…)            â”‚
â”‚ Phase 6: Acceptance Criteria âœ…        â”‚
â”‚   - All 5 criteria met                 â”‚
â”‚ Phase 7: Definition of Done âœ…         â”‚
â”‚   - All 7 DoD items complete           â”‚
â”‚ Phase 8: Commit Ready âœ…               â”‚
â”‚   - Message informative                â”‚
â”‚   - Code-Mapping prepared              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸŽ‰ QGD PASSED! Ready to Commit

Next: Commit and update BACKLOG.md
```

---

## ðŸš¨ Critical Validation Failures

**INSTANT BLOCKS (Cannot Proceed):**

1. **âŒ Tests Not Written**
   ```
   BLOCK: Cannot proceed past Phase 4 without tests
   REASON: Test-Driven Development is MANDATORY
   ACTION: Write ALL tests from Test Plan
   ```

2. **âŒ Tests Not Executed**
   ```
   BLOCK: Cannot mark task complete without test execution
   REASON: Test execution is MANDATORY
   ACTION: Run ALL tests (unit + integration + coverage)
   ```

3. **âŒ Tests Failing**
   ```
   BLOCK: Cannot commit with failing tests
   REASON: Only passing tests can be committed
   ACTION: Create Error Log â†’ Notify @debugger â†’ STOP
   ```

4. **âŒ Coverage Below 90%**
   ```
   BLOCK: Cannot proceed with insufficient coverage
   REASON: >90% coverage is MANDATORY
   ACTION: Add tests to increase coverage
   ```

5. **âŒ Error Log Not Created (when tests fail)**
   ```
   BLOCK: Cannot continue without Error Log
   REASON: Debugging requires documentation
   ACTION: Create complete Error Log â†’ Notify @debugger
   ```

---

## ðŸ’¬ Validation Message Formats

### Success Format:

```
âœ… {PHASE}

Validation successful:
  âœ… {Check 1}
  âœ… {Check 2}

Status: Ready for {Next Phase}
```

### Critical Block Format:

```
âŒ CRITICAL: {PHASE} BLOCKED

Blocking Issue:
  âŒ {Issue Description}

Impact: {Impact Description}

Action Required:
  1. {Specific Action 1}
  2. {Specific Action 2}

CANNOT PROCEED until resolved!
```

---

## ðŸ”„ Integration Points

### Mit Architect:

```
Architect erstellt Task
  â†“
Includes Test Plan (MANDATORY)
  â†“
Developer reads Task
  â†“
Validates Test Plan presence
  â†“
If missing â†’ Notify @architect
```

### Mit Debugger:

```
Developer runs tests
  â†“
Tests fail âŒ
  â†“
Create Error Log (MANDATORY)
  â†“
Notify @debugger
  â†“
STOP task execution
  â†“
Wait for @debugger fix
```

---

## ðŸ“‹ Zusammenfassung

Diese Instructions stellen sicher:

âœ… **Test-First Approach** - Tests sind MANDATORY, nicht optional  
âœ… **Quality Enforcement** - Clean Code + Type Hints + Validation  
âœ… **Comprehensive Testing** - ALL Tests run, >90% Coverage  
âœ… **Error Handling** - Error Logs bei Test-Failures  
âœ… **Documentation** - Code, Tests, Commits vollstÃ¤ndig dokumentiert  
âœ… **No Shortcuts** - Kein Code shipped ohne Tests  

**Ziel:** Stelle sicher, dass JEDER Task dem Quality-Standard entspricht - mit MANDATORY Testing als Fundament!

---

**Version:** 1.0  
**Last Updated:** 2025-10-07  
**Critical Feature:** Test-Enforcement (MANDATORY)  
**Integration:** Works with developer.chatmode.md and debugger.chatmode.md